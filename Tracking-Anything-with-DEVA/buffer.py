import numpy as np
import random
import torch
from collections import deque, namedtuple
import os
import cv2
import re

class ReplayBuffer:
    """Fixed-size buffer to store experience tuples with batch-wise file loading."""

    def __init__(self, buffer_size, batch_size, device, lstm_seq_len, config, load_all_to_memory=False):
        """Initialize a ReplayBuffer object.
        Params
        ======
            buffer_size (int): maximum size of buffer
            batch_size (int): size of each training batch
            device: device to store tensors
            lstm_seq_len (int): length of LSTM sequence
            config: configuration object
            load_all_to_memory (bool): if True, load all data to memory first
        """
        self.device = device
        self.memory = deque(maxlen=buffer_size)  
        self.batch_size = batch_size
        # ä¿®æ”¹Experienceç±»ï¼Œæ·»åŠ task_embeddingå­—æ®µç”¨äºå­˜å‚¨ä»»åŠ¡åµŒå…¥å‘é‡
        self.experience = namedtuple("Experience", field_names=["state", "action", "reward", "next_state", "done", "task_embedding"])
        self.batch_id = []
        self.st_id = []
        self.lstm_seq_len = lstm_seq_len
        self.input_type = config.input_type
        self.load_all_to_memory = load_all_to_memory
        
        # æ–°å¢ï¼šæ–‡ä»¶ç®¡ç†ç›¸å…³
        self.data_path = None
        self.file_list = []
        self.current_batch_files = []
        self.current_batch_data = []
        self.files_per_batch = batch_size  # æ¯æ¬¡åŠ è½½batch_sizeä¸ªæ–‡ä»¶
        self.task_embeddings_dict = None
        self.name_to_id_map = None
        
        # å…¨å†…å­˜æ¨¡å¼ç›¸å…³
        self.all_data_loaded = False
        self.all_transitions = []  # å­˜å‚¨æ‰€æœ‰è½¬æ¢æ•°æ®
        
        # ğŸ”¥ é€Ÿåº¦æ¡£ä½åˆ°å®é™…é€Ÿåº¦å€¼çš„æ˜ å°„
        self.velocity_mapping = {
            '1': '100',  # v1 â†’ v100
            '2': '200',  # v2 â†’ v200
            '3': '300',  # v3 â†’ v300
            '4': '400',  # v4 â†’ v400
        }
        self.angular_velocity_mapping = {
            '1': '15',   # a1 â†’ a15
            '2': '30',   # a2 â†’ a30
            '3': '60',   # a3 â†’ a60
            '4': '90',   # a4 â†’ a90
        }
    
    def _convert_velocity_to_actual(self, linear_v_raw, angular_v_raw):
        """
        å°†æ¡£ä½ç¼–å·è½¬æ¢ä¸ºå®é™…é€Ÿåº¦å€¼
        
        Args:
            linear_v_raw: åŸå§‹çº¿é€Ÿåº¦å€¼ï¼ˆå¯èƒ½æ˜¯æ¡£ä½ç¼–å·1-4æˆ–å®é™…å€¼100-400ï¼‰
            angular_v_raw: åŸå§‹è§’é€Ÿåº¦å€¼ï¼ˆå¯èƒ½æ˜¯æ¡£ä½ç¼–å·1-4æˆ–å®é™…å€¼15-90ï¼‰
        
        Returns:
            (linear_v, angular_v): æ ¼å¼åŒ–çš„é€Ÿåº¦å­—ç¬¦ä¸²ï¼Œå¦‚ ('v100', 'a15')
        """
        # è½¬æ¢çº¿é€Ÿåº¦
        if linear_v_raw in self.velocity_mapping:
            linear_v = f"v{self.velocity_mapping[linear_v_raw]}"
        else:
            # å·²ç»æ˜¯å®é™…é€Ÿåº¦å€¼ï¼Œç›´æ¥ä½¿ç”¨
            linear_v = f"v{linear_v_raw}"
        
        # è½¬æ¢è§’é€Ÿåº¦
        if angular_v_raw in self.angular_velocity_mapping:
            angular_v = f"a{self.angular_velocity_mapping[angular_v_raw]}"
        else:
            # å·²ç»æ˜¯å®é™…é€Ÿåº¦å€¼ï¼Œç›´æ¥ä½¿ç”¨
            angular_v = f"a{angular_v_raw}"
        
        return linear_v, angular_v

    def set_data_path(self, data_path, task_embeddings_dict=None, name_to_id_map=None):
        """è®¾ç½®æ•°æ®è·¯å¾„å¹¶è·å–æ–‡ä»¶åˆ—è¡¨"""
        self.data_path = data_path
        self.task_embeddings_dict = task_embeddings_dict
        self.name_to_id_map = name_to_id_map
        self.file_list = [f for f in os.listdir(data_path) if f.endswith('.pt')]
        self.file_list.sort()
        # print(f"Found {len(self.file_list)} files in {data_path}")
        
        if self.load_all_to_memory:
            self._load_all_data_to_memory()
        else:
            self._load_new_batch()

    def _load_new_batch(self):
        """åŠ è½½æ–°çš„ä¸€æ‰¹æ–‡ä»¶åˆ°å†…å­˜"""
        if not self.file_list:
            print("No files available to load")
            return
            
        # éšæœºé€‰æ‹©batch_sizeä¸ªæ–‡ä»¶
        if len(self.file_list) >= self.files_per_batch:
            selected_files = random.sample(self.file_list, self.files_per_batch)
        else:
            selected_files = self.file_list
            
        # print(f"Loading new batch: {len(selected_files)} files")
        self.current_batch_files = selected_files
        self.current_batch_data = []
        
        # æ¸…ç©ºä¹‹å‰çš„buffer
        self.memory.clear()
        
        # è®°å½•ä»»åŠ¡ç±»å‹å’Œæ•°æ®
        task_data = {}
        task_ids = {}
        
        # åŠ è½½é€‰ä¸­çš„æ–‡ä»¶
        for file_name in selected_files:
            # print(f"  Loading: {file_name}")
            file_path = os.path.join(self.data_path, file_name)
            
            # ä»æ–‡ä»¶åæ¨æ–­ä»»åŠ¡ç±»å‹ï¼ˆ4ç»´ï¼štracker2target_v1a2æ ¼å¼ï¼‰
            # å…ˆæå–åŸºæœ¬çš„x2yæ ¼å¼
            match = re.search(r'([a-z0-9]+2[a-z0-9]+)', file_name.lower())
            if not match:
                print(f"æ— æ³•ä»æ–‡ä»¶åæå–ä»»åŠ¡å(æœŸæœ› X2Y å½¢å¼): {file_name}ï¼Œè·³è¿‡è¯¥æ–‡ä»¶")
                continue
            base_task_name = match.group(1)
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«é€Ÿåº¦ä¿¡æ¯ï¼ˆv1a2æ ¼å¼ï¼‰
            velocity_match = re.search(r'v(\d+)a(\d+)', file_name.lower())
            if velocity_match:
                # ğŸ”¥ ä½¿ç”¨è¾…åŠ©å‡½æ•°è½¬æ¢æ¡£ä½ç¼–å·ä¸ºå®é™…é€Ÿåº¦å€¼
                linear_v, angular_v = self._convert_velocity_to_actual(
                    velocity_match.group(1), 
                    velocity_match.group(2)
                )
                task_name = f"{base_task_name}_{linear_v}{angular_v}"
            else:
                # å…¼å®¹æ—§æ ¼å¼ï¼šlevel1/level2/level3 æ˜ å°„åˆ°å®é™…é€Ÿåº¦å€¼
                if 'level3' in file_name.lower():
                    task_name = f"{base_task_name}_v300a60"  # level3 â†’ v300a60
                elif 'level2' in file_name.lower():
                    task_name = f"{base_task_name}_v200a30"  # level2 â†’ v200a30
                elif 'level1' in file_name.lower():
                    task_name = f"{base_task_name}_v100a15"  # level1 â†’ v100a15
                else:
                    # é»˜è®¤ä¸ºv100a15
                    task_name = f"{base_task_name}_v100a15"
            
            # ä½¿ç”¨é¢„ç”Ÿæˆä»»åŠ¡åµŒå…¥ç›®å½•ä¸­çš„ä»»åŠ¡å->IDæ˜ å°„
            if self.name_to_id_map is None:
                print("é”™è¯¯ï¼šæœªèƒ½åŠ è½½ä»»åŠ¡åç§°åˆ°IDçš„æ˜ å°„ã€‚è¯·æ£€æŸ¥ task_embeddings_dirã€‚")
                continue
            if task_name not in self.name_to_id_map:
                print(f"è­¦å‘Šï¼šä»»åŠ¡å {task_name} ä¸åœ¨ä»»åŠ¡åµŒå…¥æ˜ å°„ä¸­ï¼Œè·³è¿‡è¯¥æ–‡ä»¶")
                continue
            current_task_id = int(self.name_to_id_map[task_name])
            # ç»´æŠ¤æœ¬åœ°task_idsä»…ç”¨äºæ—¥å¿—
            task_ids[task_name] = current_task_id
            
            # åŠ è½½ .pt æ–‡ä»¶
            try:
                loaded_data = torch.load(file_path)
            except Exception as e:
                print(f"æ ‡å‡†åŠ è½½å¤±è´¥: {e}ï¼Œå°è¯•ä½¿ç”¨pickle_module=None")
                loaded_data = torch.load(file_path, pickle_module=None)
                
            if isinstance(loaded_data, list):
                frames = [frame for frame in loaded_data if frame]  
            else:
                frames = [loaded_data]
            
            # å¤„ç†å›¾åƒæ•°æ®
            if ('deva' in self.input_type.lower() or 'image' in self.input_type.lower() or 'mask' in self.input_type.lower()):
                state_tmp = np.array([np.array(frame['mask'][:, :, 0:3]) for frame in frames])[:-1]
                goal_tmp = np.array([np.array(frame['goal'][:, :, 0:3]) for frame in frames])[:-1]
                next_state_tmp = np.array([np.array(frame['mask'][:, :, 0:3]) for frame in frames])[1:]
            elif 'devadepth' in self.input_type.lower() or 'rgbd' in self.input_type.lower():
                state_tmp = np.array([np.array(frame['image'][:, :, 0:4]) for frame in frames])[:-1]
                next_state_tmp = np.array([np.array(frame['image'][:, :, 0:4]) for frame in frames])[1:]
            
            # è·å–åŠ¨ä½œä¸å¥–åŠ±ä¿¡æ¯
            act_tmp = np.array([np.array(frame['action']) for frame in frames])[:-1].squeeze(axis=1)
            
            # è®¡ç®—IoUå¥–åŠ±
            re_iou = np.array([
                self._reward_cal(state_tmp[i], goal_tmp[i])
                for i in range(len(state_tmp))
            ])
            # re_iou = np.array([np.array(frame['reward']) for frame in frames]).squeeze()[:-1]
            
            # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´
            assert state_tmp.shape[0] == next_state_tmp.shape[0] and re_iou.shape[0] == next_state_tmp.shape[0] and \
                next_state_tmp.shape[0] == act_tmp.shape[0], "æ•°æ®é•¿åº¦ä¸åŒ¹é…ï¼"
            
            # å°†å½“å‰ä»»åŠ¡çš„æ•°æ®æ·»åŠ åˆ°å­—å…¸ä¸­
            if task_name not in task_data:
                task_data[task_name] = []
            
            # éå†æ‰€æœ‰æ—¶é—´æ­¥ï¼Œå°†æ•°æ®åŠ å…¥ bufferï¼ˆä¸è½¬ç§»åˆ°GPUï¼Œä¿æŒåœ¨CPUï¼‰
            for i in range(state_tmp.shape[0]):
                # è®¾ç½® done æ ‡å¿—
                if i % state_tmp.shape[0] == 0 and i > 0:
                    done = True
                else:
                    done = False
                
                # è®°å½•ä»»åŠ¡å’Œç›¸åº”çš„è®­ç»ƒæ ·æœ¬
                task_data[task_name].append({
                    'state': np.array(cv2.resize(state_tmp[i], (64, 64)).transpose(2, 0, 1)),
                    'action': act_tmp[i],
                    'reward': np.array(re_iou[i]),
                    'next_state': np.array(cv2.resize(next_state_tmp[i], (64, 64)).transpose(2, 0, 1)),
                    'done': np.array(done),
                    'task_id': current_task_id,
                    'task_name': task_name
                })
                
                # è·å–å½“å‰ä»»åŠ¡çš„åµŒå…¥
                task_embedding = None
                if self.task_embeddings_dict is not None and current_task_id in self.task_embeddings_dict:
                    task_embedding = self.task_embeddings_dict[current_task_id]
                
                # ä¿æŒåœ¨CPUï¼Œä¸è½¬ç§»åˆ°GPU
                state = torch.from_numpy(np.array(cv2.resize(state_tmp[i], (64, 64)).transpose(2, 0, 1))).float()
                action = torch.from_numpy(act_tmp[i]).float()
                reward = torch.from_numpy(np.array(re_iou[i])).float()
                next_state = torch.from_numpy(np.array(cv2.resize(next_state_tmp[i], (64, 64)).transpose(2, 0, 1))).float()
                done_tensor = torch.from_numpy(np.array(done)).float()
                
                self.add(state, action, reward, next_state, done_tensor, task_embedding)
        
        # print(f"Loaded {len(self.memory)} transitions from {len(selected_files)} files")
        # print(f"Current buffer size: {len(self.memory)}")
        # print(f"è¯†åˆ«åˆ°çš„ä»»åŠ¡ç±»å‹: {list(task_ids.keys())}")
        # print(f"ä»»åŠ¡IDæ˜ å°„: {task_ids}")

    def _load_all_data_to_memory(self):
        """ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ•°æ®åˆ°å†…å­˜"""
        print(f"Loading all {len(self.file_list)} files to memory...")
        self.all_transitions = []
        
        for file_idx, file_name in enumerate(self.file_list):
            if file_idx % 100 == 0:
                print(f"Loading file {file_idx}/{len(self.file_list)}: {file_name}")
                
            file_path = os.path.join(self.data_path, file_name)
            
            # ä»æ–‡ä»¶åæ¨æ–­ä»»åŠ¡ç±»å‹ï¼ˆ4ç»´ï¼štracker2target_v1a2æ ¼å¼ï¼‰
            # å…ˆæå–åŸºæœ¬çš„x2yæ ¼å¼
            match = re.search(r'([a-z0-9]+2[a-z0-9]+)', file_name.lower())
            if not match:
                print(f"æ— æ³•ä»æ–‡ä»¶åæå–ä»»åŠ¡å(æœŸæœ› X2Y å½¢å¼): {file_name}ï¼Œè·³è¿‡è¯¥æ–‡ä»¶")
                continue
            base_task_name = match.group(1)
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«é€Ÿåº¦ä¿¡æ¯ï¼ˆv1a2æ ¼å¼ï¼‰
            velocity_match = re.search(r'v(\d+)a(\d+)', file_name.lower())
            if velocity_match:
                # ğŸ”¥ ä½¿ç”¨è¾…åŠ©å‡½æ•°è½¬æ¢æ¡£ä½ç¼–å·ä¸ºå®é™…é€Ÿåº¦å€¼
                linear_v, angular_v = self._convert_velocity_to_actual(
                    velocity_match.group(1), 
                    velocity_match.group(2)
                )
                task_name = f"{base_task_name}_{linear_v}{angular_v}"
            else:
                # å…¼å®¹æ—§æ ¼å¼ï¼šlevel1/level2/level3 æ˜ å°„åˆ°å®é™…é€Ÿåº¦å€¼
                if 'level3' in file_name.lower():
                    task_name = f"{base_task_name}_v300a60"  # level3 â†’ v300a60
                elif 'level2' in file_name.lower():
                    task_name = f"{base_task_name}_v200a30"  # level2 â†’ v200a30
                elif 'level1' in file_name.lower():
                    task_name = f"{base_task_name}_v100a15"  # level1 â†’ v100a15
                else:
                    # é»˜è®¤ä¸ºv100a15
                    task_name = f"{base_task_name}_v100a15"
            
            # ä½¿ç”¨é¢„ç”Ÿæˆä»»åŠ¡åµŒå…¥ç›®å½•ä¸­çš„ä»»åŠ¡å->IDæ˜ å°„
            if self.name_to_id_map is None:
                print("é”™è¯¯ï¼šæœªèƒ½åŠ è½½ä»»åŠ¡åç§°åˆ°IDçš„æ˜ å°„ã€‚è¯·æ£€æŸ¥ task_embeddings_dirã€‚")
                continue
            if task_name not in self.name_to_id_map:
                print(f"è­¦å‘Šï¼šä»»åŠ¡å {task_name} ä¸åœ¨ä»»åŠ¡åµŒå…¥æ˜ å°„ä¸­ï¼Œè·³è¿‡è¯¥æ–‡ä»¶")
                continue
            current_task_id = int(self.name_to_id_map[task_name])
            
            # åŠ è½½ .pt æ–‡ä»¶
            try:
                loaded_data = torch.load(file_path)
            except Exception as e:
                print(f"æ ‡å‡†åŠ è½½å¤±è´¥: {e}ï¼Œå°è¯•ä½¿ç”¨pickle_module=None")
                loaded_data = torch.load(file_path, pickle_module=None)
                
            if isinstance(loaded_data, list):
                frames = [frame for frame in loaded_data if frame]  
            else:
                frames = [loaded_data]
            
            # å¤„ç†å›¾åƒæ•°æ®
            if ('deva' in self.input_type.lower() or 'image' in self.input_type.lower() or 'mask' in self.input_type.lower()):
                state_tmp = np.array([np.array(frame['mask'][:, :, 0:3]) for frame in frames])[:-1]
                goal_tmp = np.array([np.array(frame['goal'][:, :, 0:3]) for frame in frames])[:-1]
                next_state_tmp = np.array([np.array(frame['mask'][:, :, 0:3]) for frame in frames])[1:]
            elif 'devadepth' in self.input_type.lower() or 'rgbd' in self.input_type.lower():
                state_tmp = np.array([np.array(frame['image'][:, :, 0:4]) for frame in frames])[:-1]
                next_state_tmp = np.array([np.array(frame['image'][:, :, 0:4]) for frame in frames])[1:]
            
            # è·å–åŠ¨ä½œä¸å¥–åŠ±ä¿¡æ¯
            act_tmp = np.array([np.array(frame['action']) for frame in frames])[:-1].squeeze(axis=1)
            re_iou = np.array([
                self._reward_cal(state_tmp[i], goal_tmp[i])
                for i in range(len(state_tmp))
            ])
            # re_iou = np.array([np.array(frame['reward']) for frame in frames]).squeeze()[:-1]
            
            # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´
            assert state_tmp.shape[0] == next_state_tmp.shape[0] and re_iou.shape[0] == next_state_tmp.shape[0] and \
                next_state_tmp.shape[0] == act_tmp.shape[0], "æ•°æ®é•¿åº¦ä¸åŒ¹é…ï¼"
            
            # è·å–å½“å‰ä»»åŠ¡çš„åµŒå…¥
            task_embedding = None
            if self.task_embeddings_dict is not None and current_task_id in self.task_embeddings_dict:
                task_embedding = self.task_embeddings_dict[current_task_id]
            
            # å°†æ‰€æœ‰è½¬æ¢æ·»åŠ åˆ°å…¨å†…å­˜å­˜å‚¨
            for i in range(state_tmp.shape[0]):
                if i % state_tmp.shape[0] == 0 and i > 0:
                    done = True
                else:
                    done = False
                    
                # ä¿æŒåœ¨CPUï¼Œä¸è½¬ç§»åˆ°GPU
                state = torch.from_numpy(np.array(cv2.resize(state_tmp[i], (64, 64)).transpose(2, 0, 1))).float()
                action = torch.from_numpy(act_tmp[i]).float()
                reward = torch.from_numpy(np.array(re_iou[i])).float()
                next_state = torch.from_numpy(np.array(cv2.resize(next_state_tmp[i], (64, 64)).transpose(2, 0, 1))).float()
                done_tensor = torch.from_numpy(np.array(done)).float()
                
                self.all_transitions.append((state, action, reward, next_state, done_tensor, task_embedding))
        
        self.all_data_loaded = True
        print(f"Loaded {len(self.all_transitions)} transitions to memory")

    def refresh_batch(self):
        """åˆ·æ–°batchï¼ŒåŠ è½½æ–°çš„æ–‡ä»¶"""
        if self.load_all_to_memory:
            # å…¨å†…å­˜æ¨¡å¼ä¸‹ä¸éœ€è¦åˆ·æ–°batch
            pass
        else:
            self._load_new_batch()

    def _reward_cal(self, state, goal):
        """è®¡ç®—IoUå¥–åŠ±"""
        if state.max() == 255:
            boxA = self._get_bounding_box(state)
            if boxA is None:
                return 0
            boxB = self._get_bounding_box(goal)
            if boxB is None:
                return 0

            # è®¡ç®—äº¤é›†
            xA = max(boxA[0], boxB[0])
            yA = max(boxA[1], boxB[1])
            xB = min(boxA[2], boxB[2])
            yB = min(boxA[3], boxB[3])

            interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)
            boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)
            boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)

            iou = interArea / float(boxAArea + boxBArea - interArea)
            total_reward = iou
        else:
            total_reward = 0

        return total_reward

    def _get_bounding_box(self, mask_image):
        """è·å–è¾¹ç•Œæ¡†"""
        target_pixels = np.where(np.all(mask_image == [255, 255, 255], axis=-1))

        if len(target_pixels[0]) == 0:
            return None

        y_min = np.min(target_pixels[0])
        y_max = np.max(target_pixels[0])
        x_min = np.min(target_pixels[1])
        x_max = np.max(target_pixels[1])

        return x_min, y_min, x_max, y_max

    def add(self, state, action, reward, next_state, done, task_embedding=None):
        """Add a new experience to memory.
        
        Args:
            state: çŠ¶æ€
            action: åŠ¨ä½œ
            reward: å¥–åŠ±
            next_state: ä¸‹ä¸€çŠ¶æ€
            done: æ˜¯å¦ç»“æŸ
            task_embedding: ä»»åŠ¡åµŒå…¥å‘é‡ï¼Œé»˜è®¤ä¸ºNone
        """
        e = self.experience(
            state,
            action,
            reward,
            next_state,
            done,
            task_embedding)
        self.memory.append(e)
    
    def sample(self):
        """ä»ç¼“å†²åŒºä¸­é‡‡æ ·ä¸€æ‰¹æ•°æ®ï¼Œæ— éœ€æŒ‡å®šä»»åŠ¡ID"""
        if self.load_all_to_memory:
            # å…¨å†…å­˜æ¨¡å¼ï¼šç›´æ¥ä»æ‰€æœ‰æ•°æ®ä¸­é‡‡æ ·
            if not self.all_data_loaded:
                raise RuntimeError("All data not loaded yet!")
                
            # for lstm,seq frame input
            if ('cnn' in self.input_type.lower() and 'lstm' in self.input_type.lower()) or 'mlp' in self.input_type.lower() or 'clip' in self.input_type.lower():
                states_test = []
                actions_test = []
                rewards_test = []
                next_states_test = []
                done_test = []
                task_embeddings = []
                
                for i in range(self.batch_size):
                    # éšæœºé€‰æ‹©èµ·å§‹ä½ç½®
                    start_idx = random.randint(0, len(self.all_transitions) - self.lstm_seq_len)
                    experiences_test = []
                    
                    for j in range(self.lstm_seq_len):
                        experiences_test.append(self.all_transitions[start_idx + j])
                    
                    states_test.append([e[0] for e in experiences_test])
                    actions_test.append([e[1] for e in experiences_test])
                    rewards_test.append([e[2] for e in experiences_test])
                    next_states_test.append([e[3] for e in experiences_test])
                    done_test.append([e[4] for e in experiences_test])
                    
                    # æå–ä»»åŠ¡åµŒå…¥ä¿¡æ¯
                    task_emb = experiences_test[0][5]  # task_embedding is at index 5
                    if task_emb is not None:
                        if not isinstance(task_emb, torch.Tensor):
                            task_emb = torch.tensor(task_emb, device=self.device)
                        task_embeddings.append(task_emb)
                    else:
                        task_embeddings.append(None)

                states = torch.stack([torch.stack(s) for s in states_test])
                actions = torch.stack([torch.stack(a) for a in actions_test])
                rewards = torch.stack([torch.stack(r) for r in rewards_test])
                next_states = torch.stack([torch.stack(n) for n in next_states_test])
                dones = torch.stack([torch.stack(d) for d in done_test])

                # åœ¨sampleæ—¶è½¬ç§»åˆ°GPU
                states = states.to(self.device)
                actions = actions.to(self.device)
                rewards = rewards.to(self.device)
                next_states = next_states.to(self.device)
                dones = dones.to(self.device)
                
                # å¤„ç†ä»»åŠ¡åµŒå…¥
                if all(emb is None for emb in task_embeddings):
                    return (states, actions, rewards, next_states, dones)
                else:
                    valid_embs = [emb for emb in task_embeddings if emb is not None]
                    if valid_embs:
                        emb_dim = valid_embs[0].shape[-1]
                        batch_task_embeddings = torch.zeros((self.batch_size, emb_dim), device=self.device)
                        for i, emb in enumerate(task_embeddings):
                            if emb is not None:
                                batch_task_embeddings[i] = emb
                        return (states, actions, rewards, next_states, dones, batch_task_embeddings)
                    else:
                        return (states, actions, rewards, next_states, dones)
            else:
                # éLSTMæ¨¡å¼ï¼šéšæœºé‡‡æ ·
                batch = random.sample(self.all_transitions, self.batch_size)
                
                states = torch.stack([e[0] for e in batch])
                actions = torch.stack([e[1] for e in batch])
                rewards = torch.stack([e[2] for e in batch])
                next_states = torch.stack([e[3] for e in batch])
                dones = torch.stack([e[4] for e in batch])
                
                # å¤„ç†ä»»åŠ¡åµŒå…¥
                task_embeddings = [e[5] for e in batch]
                
                # è½¬ç§»åˆ°GPU
                states = states.to(self.device)
                actions = actions.to(self.device)
                rewards = rewards.to(self.device)
                next_states = next_states.to(self.device)
                dones = dones.to(self.device)
                
                if all(emb is None for emb in task_embeddings):
                    return (states, actions, rewards, next_states, dones)
                else:
                    valid_embs = [emb for emb in task_embeddings if emb is not None]
                    if valid_embs:
                        emb_dim = valid_embs[0].shape[-1]
                        batch_task_embeddings = torch.zeros((self.batch_size, emb_dim), device=self.device)
                        for i, emb in enumerate(task_embeddings):
                            if emb is not None:
                                batch_task_embeddings[i] = emb
                        return (states, actions, rewards, next_states, dones, batch_task_embeddings)
                    else:
                        return (states, actions, rewards, next_states, dones)
        else:
            
            # åŸæœ‰çš„batchæ¨¡å¼
            if len(self.memory) == 0:
                self._load_new_batch()
                
            # for lstm,seq frame input
            if ('cnn' in self.input_type.lower() and 'lstm' in self.input_type.lower()) or 'mlp' in self.input_type.lower() or 'clip' in self.input_type.lower():
                states_test = []
                actions_test = []
                rewards_test = []
                next_states_test = []
                done_test = []
                self.batch_id = []
                self.st_id = []
                
                for i in range(self.batch_size):
                    self.st_id.append(random.randint(0, 349 - self.lstm_seq_len))
                    self.batch_id.append(random.randint(0, int(len(self.memory)/349) - 1))

                for i in range(self.batch_size):
                    experiences_test = []
                    for j in range(0, self.lstm_seq_len):
                        experiences_test.append(self.memory[self.batch_id[i]*349+self.st_id[i]])
                        self.st_id[i] += 1

                    states_test.append([e.state for e in experiences_test if e is not None])
                    actions_test.append([e.action for e in experiences_test if e is not None])
                    rewards_test.append([e.reward for e in experiences_test if e is not None])
                    next_states_test.append([e.next_state for e in experiences_test if e is not None])
                    done_test.append([e.done for e in experiences_test if e is not None])
                    
                    # æå–ä»»åŠ¡åµŒå…¥ä¿¡æ¯ï¼Œå¦‚æœå­˜åœ¨çš„è¯
                    if hasattr(experiences_test[0], 'task_embedding') and experiences_test[0].task_embedding is not None:
                        # å‡è®¾åŒä¸€åºåˆ—å†…ä»»åŠ¡åµŒå…¥ç›¸åŒï¼Œåªå–ç¬¬ä¸€ä¸ª
                        task_emb = experiences_test[0].task_embedding
                        if not isinstance(task_emb, torch.Tensor):
                            task_emb = torch.tensor(task_emb, device=self.device)
                    else:
                        # å¦‚æœæ²¡æœ‰ä»»åŠ¡åµŒå…¥ï¼Œåˆ›å»ºä¸€ä¸ªå€¼ä¸ºNoneçš„å ä½ç¬¦
                        task_emb = None

                states = torch.stack([torch.stack(s) for s in states_test])
                actions = torch.stack([torch.stack(a) for a in actions_test])
                rewards = torch.stack([torch.stack(r) for r in rewards_test])
                next_states = torch.stack([torch.stack(n) for n in next_states_test])
                dones = torch.stack([torch.stack(d) for d in done_test])
                
                # å¤„ç†ä»»åŠ¡åµŒå…¥
                task_embeddings = []
                for i in range(self.batch_size):
                    if hasattr(self.memory[self.batch_id[i]*349+self.st_id[i]-self.lstm_seq_len], 'task_embedding'):
                        emb = self.memory[self.batch_id[i]*349+self.st_id[i]-self.lstm_seq_len].task_embedding
                        if emb is not None:
                            if not isinstance(emb, torch.Tensor):
                                emb = torch.tensor(emb, device=self.device)
                            task_embeddings.append(emb)
                        else:
                            task_embeddings.append(None)
                    else:
                        task_embeddings.append(None)
                
                # åœ¨sampleæ—¶è½¬ç§»åˆ°GPU
                states = states.to(self.device)
                actions = actions.to(self.device)
                rewards = rewards.to(self.device)
                next_states = next_states.to(self.device)
                dones = dones.to(self.device)
                
                # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰çš„ä»»åŠ¡åµŒå…¥éƒ½æ˜¯None
                if all(emb is None for emb in task_embeddings):
                    # å¦‚æœéƒ½æ˜¯Noneï¼Œåˆ™ä¸è¿”å›ä»»åŠ¡åµŒå…¥ä¿¡æ¯
                    return (states, actions, rewards, next_states, dones)
                else:
                    # å¦åˆ™ï¼Œåœ¨ç»“æœå…ƒç»„ä¸­æ·»åŠ ä»»åŠ¡åµŒå…¥ä¿¡æ¯
                    # å¯¹äºNoneçš„ä»»åŠ¡åµŒå…¥ï¼Œä½¿ç”¨é›¶å‘é‡æ›¿ä»£
                    valid_embs = [emb for emb in task_embeddings if emb is not None]
                    if valid_embs:
                        emb_dim = valid_embs[0].shape[-1]
                        batch_task_embeddings = torch.zeros((self.batch_size, emb_dim), device=self.device)
                        for i, emb in enumerate(task_embeddings):
                            if emb is not None:
                                batch_task_embeddings[i] = emb
                        return (states, actions, rewards, next_states, dones, batch_task_embeddings)
                    else:
                        return (states, actions, rewards, next_states, dones)

    def __len__(self):
        """Return the current size of internal memory."""
        return len(self.memory)